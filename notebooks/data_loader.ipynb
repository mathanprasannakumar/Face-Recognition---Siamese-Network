{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df2a9fe5-ac75-4f81-877f-81d5ef57eb08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import gdown\n",
    "import tqdm\n",
    "from PIL import Image\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c62d35-c7a2-46c0-8a32-cce9e13c0ba0",
   "metadata": {},
   "source": [
    "### Download the lfwa dataset\n",
    "\n",
    "<ul>\n",
    "    <li>Labeled Faces in the wild</li>\n",
    "    <li>It has  5,749 people pictures</li>\n",
    "    <li>Total no of images = 13,233 </li>\n",
    "    <li>Here in lfwa dataset all the images are greyscaled and aligned which will improve the  performance of the model\n",
    "    </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add6b574-3bda-44dd-bb97-f92853d360ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# link to the dataset\n",
    "url = 'https://drive.google.com/u/0/uc?id=1p1wjaqpTh_5RHfJu4vUh8JJCdKwYMHCp&export=download'\n",
    "\n",
    "# downloading the zip file in the current directory\n",
    "gdown.download(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9004627f-f22b-40d8-84b6-f3079e060dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip lfwa.zip"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4189bb89-6975-422c-99ea-859c7d5b663e",
   "metadata": {},
   "source": [
    "<ul>\n",
    "    <li>train.txt --> It has 2200 pair of image details ,Among 2200 , 1100 are similar person details and 1100 are disimilar person details\n",
    "    </li>\n",
    "    <li>test.txt --> it has 1000 pair of image details, Among 1000, 500 are similar person details and 500 are disimilar person details </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8634200d-7fb2-475f-8472-5382931ba93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train ='train'\n",
    "test = 'test'\n",
    "width = 105\n",
    "height = 105\n",
    "cells = 1\n",
    "datapath = './dataset/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4cf07ba5-1b27-49a8-821e-709df3e27cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def _open_image(path):\n",
    "    \"\"\"\n",
    "    Using the Image library we open the image in the given path. The path must lead to a .jpg file.\n",
    "    We then resize it to 105x105 like in the paper (the dataset contains 250x250 images.)\n",
    "\n",
    "    Returns the image as a numpy array.\n",
    "    \"\"\"\n",
    "    image = Image.open(path)\n",
    "    image = image.resize((width,height))\n",
    "    data = np.asarray(image)\n",
    "    data = np.array(data, dtype='float64')\n",
    "    return data\n",
    "\n",
    "def convert_image_to_array(person, image_num, data_path, predict=False):\n",
    "    \"\"\"\n",
    "    Given a person, image number and datapath, returns a numpy array which represents the image.\n",
    "    predict - whether this function is called during training or testing. If called when training, we must reshape\n",
    "    the images since the given dataset is not in the correct dimensions.\n",
    "    \"\"\"\n",
    "    max_zeros = 4\n",
    "    image_num = '0' * max_zeros + image_num\n",
    "    image_num = image_num[-max_zeros:]\n",
    "    image_path = os.path.join(data_path, 'lfw2', person, f'{person}_{image_num}.jpg')\n",
    "    image_data =_open_image(image_path)\n",
    "    if not predict:\n",
    "        image_data = image_data.reshape(width,height,cells)\n",
    "    return image_data\n",
    "\n",
    "def load(set_name,datapath):\n",
    "    \"\"\"\n",
    "    Writes into the given output_path the images from the data_path.\n",
    "    dataset_type = train or test\n",
    "    \"\"\"\n",
    "    file_path = os.path.join(datapath, 'splits', f'{set_name}.txt')\n",
    "    output_path = os.path.join(datapath,f'{set_name}.pickle')\n",
    "    print(file_path)\n",
    "    print('Loading dataset...')\n",
    "    x_first = []\n",
    "    x_second = []\n",
    "    y = []\n",
    "    names = []\n",
    "    with open(file_path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "    for line in tqdm.tqdm(lines):\n",
    "        line = line.split()\n",
    "        if len(line) == 4:  # Class 0 - non-identical\n",
    "            names.append(line)\n",
    "            first_person_name, first_image_num, second_person_name, second_image_num = line[0], line[1], line[2], \\\n",
    "                                                                                           line[3]\n",
    "            first_image =convert_image_to_array(person=first_person_name,\n",
    "                                                          image_num=first_image_num,\n",
    "                                                          data_path='dataset')\n",
    "            second_image =convert_image_to_array(person=second_person_name,\n",
    "                                                           image_num=second_image_num,\n",
    "                                                           data_path='dataset')\n",
    "            x_first.append(first_image)\n",
    "            x_second.append(second_image)\n",
    "            y.append(0)\n",
    "        elif len(line) == 3:  # Class 1 - identical\n",
    "            names.append(line)\n",
    "            person_name, first_image_num, second_image_num = line[0], line[1], line[2]\n",
    "            first_image =convert_image_to_array(person=person_name,\n",
    "                                                          image_num=first_image_num,\n",
    "                                                          data_path='dataset')\n",
    "            second_image =convert_image_to_array(person=person_name,\n",
    "                                                           image_num=second_image_num,\n",
    "                                                           data_path='dataset')\n",
    "            x_first.append(first_image)\n",
    "            x_second.append(second_image)\n",
    "            y.append(1)\n",
    "    print('Done loading dataset')\n",
    "    with open(output_path, 'wb') as f:\n",
    "        pickle.dump([[x_first, x_second], y, names], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "50367989-3132-49b1-865a-3b359063e997",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./dataset/splits/train.txt\n",
      "Loading dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 2201/2201 [00:01<00:00, 1128.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done loading dataset\n"
     ]
    }
   ],
   "source": [
    "# forming train dataset \n",
    "# before loading the image plese make sure test.txt and train.txt is present inside the split folder \n",
    "load(train,datapath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1d1f99c8-39ea-47ad-b648-1787dfcccb6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./dataset/splits/test.txt\n",
      "Loading dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 1001/1001 [00:00<00:00, 1104.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done loading dataset\n"
     ]
    }
   ],
   "source": [
    "load(test,datapath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3d2875-a05e-47c7-837a-31e6d70d92e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe6dce1-68c1-4fd5-a369-5b788bbaca5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de27a3f7-f83e-4a7c-8907-6c3168b7357c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ce26c7-d6f8-48c6-9b35-367be69766b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01efe34f-27cc-4cf5-92a9-6d5a86600ce7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f77d8272-a48b-43e6-925d-6ff56bea3453",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
