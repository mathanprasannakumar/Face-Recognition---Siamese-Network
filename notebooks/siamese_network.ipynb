{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4cd86dc-ea91-48b7-8353-bd4ea7222cac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-06 21:16:24.098558: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-07-06 21:16:24.125788: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-07-06 21:16:24.126453: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-06 21:16:24.780578: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import Input, Sequential, Model\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Lambda, BatchNormalization, Activation, \\\n",
    "    Dropout\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.optimizers import Adam\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "78e57675-b797-4421-8b87-f38de8b8937e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Siamese Network\n"
     ]
    }
   ],
   "source": [
    "class SiameseNetwork(object):\n",
    "    \n",
    "    def __init__(self, seed, width, height, cells, loss, metrics, optimizer, dropout_rate):\n",
    "        \"\"\"\n",
    "        Seed - The seed used to initialize the weights\n",
    "        width, height, cells - used for defining the tensors used for the input images\n",
    "        loss, metrics, optimizer, dropout_rate - settings used for compiling the siamese model (e.g., 'Accuracy' and 'ADAM)\n",
    "        \"\"\"\n",
    "        K.clear_session()\n",
    "        self.load_file = \"weights.h5\"\n",
    "        self.seed = seed\n",
    "        self.initialize_seed()\n",
    "        self.optimizer = optimizer\n",
    "\n",
    "        # Define the matrices for the input images\n",
    "        input_shape = (width, height, cells)\n",
    "        left_input = Input(input_shape)\n",
    "        right_input = Input(input_shape)\n",
    "\n",
    "        # Get the CNN architecture as presented in the paper (read the readme for more information)\n",
    "        model = self._get_architecture(input_shape)\n",
    "        encoded_l = model(left_input)\n",
    "        encoded_r = model(right_input)\n",
    "\n",
    "        # Add a layer to combine the two CNNs\n",
    "        L1_layer = Lambda(lambda tensors: K.abs(tensors[0] - tensors[1]))\n",
    "        L1_siamese_dist = L1_layer([encoded_l, encoded_r])\n",
    "        L1_siamese_dist = Dropout(dropout_rate)(L1_siamese_dist)\n",
    "\n",
    "        # An output layer with Sigmoid activation function\n",
    "        prediction = Dense(1, activation='sigmoid', bias_initializer=self.initialize_bias)(L1_siamese_dist)\n",
    "\n",
    "        siamese_net = Model(inputs=[left_input, right_input], outputs=prediction)\n",
    "        self.siamese_net = siamese_net\n",
    "        self.siamese_net.compile(loss=loss, optimizer=optimizer, metrics=metrics)\n",
    "\n",
    "    def initialize_seed(self):\n",
    "        \"\"\"\n",
    "        Initialize seed all for environment\n",
    "        \"\"\"\n",
    "        os.environ['PYTHONHASHSEED'] = str(self.seed)\n",
    "        random.seed(self.seed)\n",
    "        np.random.seed(self.seed)\n",
    "        tf.random.set_seed(self.seed)\n",
    "\n",
    "    def initialize_weights(self, shape, dtype=None):\n",
    "        \"\"\"\n",
    "        Called when initializing the weights of the siamese model, uses the random_normal function of keras to return a\n",
    "        tensor with a normal distribution of weights.\n",
    "        \"\"\"\n",
    "        return K.random_normal(shape, mean=0.0, stddev=0.01, dtype=dtype, seed=self.seed)\n",
    "\n",
    "    def initialize_bias(self, shape, dtype=None):\n",
    "        \"\"\"\n",
    "        Called when initializing the biases of the siamese model, uses the random_normal function of keras to return a\n",
    "        tensor with a normal distribution of weights.\n",
    "        \"\"\"\n",
    "        return K.random_normal(shape, mean=0.5, stddev=0.01, dtype=dtype, seed=self.seed)\n",
    "\n",
    "    def _get_architecture(self, input_shape):\n",
    "        \"\"\"\n",
    "        Returns a Convolutional Neural Network based on the input shape given of the images. This is the CNN network\n",
    "        that is used inside the siamese model. Uses parameters from the siamese one shot paper.\n",
    "        \"\"\"\n",
    "        model = Sequential()\n",
    "        model.add(\n",
    "            Conv2D(filters=64,\n",
    "                   kernel_size=(10, 10),\n",
    "                   input_shape=input_shape,\n",
    "                   kernel_initializer=self.initialize_weights,\n",
    "                   kernel_regularizer=l2(2e-4),\n",
    "                   name='Conv1'\n",
    "                   ))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(MaxPooling2D())\n",
    "\n",
    "        model.add(\n",
    "            Conv2D(filters=128,\n",
    "                   kernel_size=(7, 7),\n",
    "                   kernel_initializer=self.initialize_weights,\n",
    "                   bias_initializer=self.initialize_bias,\n",
    "                   kernel_regularizer=l2(2e-4),\n",
    "                   name='Conv2'\n",
    "                   ))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(MaxPooling2D())\n",
    "\n",
    "        model.add(\n",
    "            Conv2D(filters=128,\n",
    "                   kernel_size=(4, 4),\n",
    "                   kernel_initializer=self.initialize_weights,\n",
    "                   bias_initializer=self.initialize_bias,\n",
    "                   kernel_regularizer=l2(2e-4),\n",
    "                   name='Conv3'\n",
    "                   ))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(MaxPooling2D())\n",
    "\n",
    "        model.add(\n",
    "            Conv2D(filters=256,\n",
    "                   kernel_size=(4, 4),\n",
    "                   kernel_initializer=self.initialize_weights,\n",
    "                   bias_initializer=self.initialize_bias,\n",
    "                   kernel_regularizer=l2(2e-4),\n",
    "                   name='Conv4'\n",
    "                   ))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Activation(\"relu\"))\n",
    "\n",
    "        model.add(Flatten())\n",
    "        model.add(\n",
    "            Dense(4096,\n",
    "                  activation='sigmoid',\n",
    "                  kernel_initializer=self.initialize_weights,\n",
    "                  kernel_regularizer=l2(2e-3),\n",
    "                  bias_initializer=self.initialize_bias))\n",
    "        return model\n",
    "\n",
    "    def _load_weights(self, weights_file):\n",
    "        \"\"\"\n",
    "        A function that attempts to load pre-existing weight files for the siamese model. If it succeeds then returns\n",
    "        True and updates the weights, otherwise False.\n",
    "        :return True if the file is already exists\n",
    "        \"\"\"\n",
    "        # self.siamese_net.summary()\n",
    "        self.load_file = weights_file\n",
    "        if os.path.exists(weights_file):  # if the file is already exists, load and return true\n",
    "            print('Loading pre-existed weights file')\n",
    "            self.siamese_net.load_weights(weights_file)\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    def fit(self, weights_file, train_path, validation_size, batch_size, epochs, early_stopping, patience, min_delta):\n",
    "        \"\"\"\n",
    "        Function for fitting the model. If the weights already exist, just return the summary of the model. Otherwise,\n",
    "        perform a whole train/validation/test split and train the model with the given parameters.\n",
    "        \"\"\"\n",
    "        with open(train_path, 'rb') as f:\n",
    "            x_train, y_train, names = pickle.load(f)\n",
    "            \n",
    "        x_train_0, x_val_0, y_train_0, y_val_0 = train_test_split(x_train[0], y_train,\n",
    "                                                                  test_size=validation_size,\n",
    "                                                                  random_state=self.seed)\n",
    "        x_train_1, x_val_1, y_train_1, y_val_1 = train_test_split(x_train[1], y_train,\n",
    "                                                                  test_size=validation_size,\n",
    "                                                                  random_state=self.seed)\n",
    "        x_train_0 = np.array(x_train_0, dtype='float64')\n",
    "        x_val_0 = np.array(x_val_0, dtype='float64')\n",
    "        x_train_1 = np.array(x_train_1, dtype='float64')\n",
    "        x_val_1 = np.array(x_val_1, dtype='float64')\n",
    "        x_train = [x_train_0, x_train_1]\n",
    "        x_val = [x_val_0, x_val_1]\n",
    "        if y_train_0 != y_train_1 and y_val_0 != y_val_1:\n",
    "            raise Exception(\"y train lists or y validation list do not equal\")\n",
    "        y_train_both = np.array(y_train_0, dtype='float64')\n",
    "        y_val_both = np.array(y_val_0, dtype='float64')\n",
    "        if not self._load_weights(weights_file=weights_file):\n",
    "            print('No such pre-existed weights file')\n",
    "            print('Beginning to fit the model')\n",
    "            callback = []\n",
    "            if early_stopping:\n",
    "                es = EarlyStopping(monitor='val_loss', min_delta=min_delta, patience=patience, mode='auto', verbose=1)\n",
    "                callback.append(es)\n",
    "            self.siamese_net.fit(x_train, y_train_both, batch_size=batch_size, epochs=epochs,\n",
    "                                 validation_data=(x_val, y_val_both), callbacks=callback, verbose=1)\n",
    "            self.siamese_net.save(\"saved_model\")\n",
    "        # evaluate on the testing set\n",
    "        loss, accuracy = self.siamese_net.evaluate(x_val, y_val_both, batch_size=batch_size)\n",
    "        print(f'Loss on Validation set: {loss}')\n",
    "        print(f'Accuracy on Validation set: {accuracy}')\n",
    "\n",
    "    def evaluate(self, test_file, batch_size):\n",
    "        \"\"\"\n",
    "        Function for evaluating the final model after training.\n",
    "        test_file - file path to the test file.\n",
    "        batch_size - the batch size used in training.\n",
    "\n",
    "        Returns the loss and accuracy results.\n",
    "        \"\"\"\n",
    "        with open(test_file, 'rb') as f:\n",
    "            x_test, y_test, names = pickle.load(f)\n",
    "        print(f'Available Metrics: {self.siamese_net.metrics_names}')\n",
    "        y_test = np.array(y_test, dtype='float64')\n",
    "        x_test[0] = np.array(x_test[0], dtype='float64')\n",
    "        x_test[1] = np.array(x_test[1], dtype='float64')\n",
    "        # evaluate on the test set\n",
    "        loss, accuracy = self.siamese_net.evaluate(x_test, y_test, batch_size=batch_size)\n",
    "        return loss, accuracy\n",
    "        \n",
    "print(\"Loaded Siamese Network\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8099bc66-4b5d-4ddc-9432-5b9804f04ae1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "posix\n",
      "Starting the experiments\n",
      "Running combination with seed_0_lr_5e-05_bs_32_ep_10_val_0.2_es_True_pa_5_md_0.01\n",
      "No such pre-existed weights file\n",
      "Beginning to fit the model\n",
      "Epoch 1/10\n",
      "55/55 [==============================] - 228s 4s/step - loss: 5.3273 - accuracy: 0.5869 - val_loss: 2.7880 - val_accuracy: 0.6386\n",
      "Epoch 2/10\n",
      "55/55 [==============================] - 224s 4s/step - loss: 1.8418 - accuracy: 0.6432 - val_loss: 1.3280 - val_accuracy: 0.6750\n",
      "Epoch 3/10\n",
      "55/55 [==============================] - 233s 4s/step - loss: 1.2396 - accuracy: 0.6574 - val_loss: 1.1899 - val_accuracy: 0.6386\n",
      "Epoch 4/10\n",
      "55/55 [==============================] - 233s 4s/step - loss: 1.1000 - accuracy: 0.6881 - val_loss: 1.1669 - val_accuracy: 0.6545\n",
      "Epoch 5/10\n",
      "55/55 [==============================] - 223s 4s/step - loss: 1.1838 - accuracy: 0.6767 - val_loss: 1.2787 - val_accuracy: 0.6318\n",
      "Epoch 6/10\n",
      "55/55 [==============================] - 214s 4s/step - loss: 1.1585 - accuracy: 0.6949 - val_loss: 1.1550 - val_accuracy: 0.6341\n",
      "Epoch 7/10\n",
      "55/55 [==============================] - 233s 4s/step - loss: 1.1826 - accuracy: 0.6892 - val_loss: 1.3233 - val_accuracy: 0.6023\n",
      "Epoch 8/10\n",
      "55/55 [==============================] - 211s 4s/step - loss: 1.1813 - accuracy: 0.7051 - val_loss: 1.2193 - val_accuracy: 0.6636\n",
      "Epoch 9/10\n",
      "55/55 [==============================] - 209s 4s/step - loss: 1.1701 - accuracy: 0.7142 - val_loss: 1.3016 - val_accuracy: 0.6432\n",
      "Epoch 10/10\n",
      "55/55 [==============================] - 209s 4s/step - loss: 1.1665 - accuracy: 0.6994 - val_loss: 1.2587 - val_accuracy: 0.6205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-06 20:22:24.211758: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,4096]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-07-06 20:22:24.871701: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,4096]\n",
      "\t [[{{node inputs}}]]\n",
      "WARNING:absl:Found untraced functions such as _update_step_xla, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_model/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 7s 473ms/step - loss: 1.2587 - accuracy: 0.6205\n",
      "Loss on Validation set: 1.2586919069290161\n",
      "Accuracy on Validation set: 0.6204545497894287\n",
      "Available Metrics: ['loss', 'accuracy']\n",
      "32/32 [==============================] - 16s 486ms/step - loss: 1.2694 - accuracy: 0.6020\n",
      "Loss on Testing set: 1.2693830728530884\n",
      "Accuracy on Testing set: 0.6019999980926514\n",
      "Total Running Time: 2249.836026906967\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_name = 'train'\n",
    "test_name = 'test'\n",
    "WIDTH = HEIGHT = 105\n",
    "CEELS = 1\n",
    "loss_type = \"binary_crossentropy\"\n",
    "validation_size = 0.2\n",
    "early_stopping = True\n",
    "\n",
    "data_path = 'dataset'\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "\n",
    "def run_combination(l, bs, ep, pat, md, seed, train_path, test_path):\n",
    "    \"\"\"\n",
    "    This function gets the parameters and run the experiment.\n",
    "    :return: loss - loss on the testing set, accuracy - accuracy on the testing set\n",
    "    \"\"\"\n",
    "    # file types\n",
    "    model_save_type = 'h5'\n",
    "    # files paths\n",
    "    initialize_seed(seed)\n",
    "    parameters_name = f'seed_{seed}_lr_{l}_bs_{bs}_ep_{ep}_val_{validation_size}_' \\\n",
    "                      f'es_{early_stopping}_pa_{pat}_md_{md}'\n",
    "    print(f'Running combination with {parameters_name}')\n",
    "    # A path for the weights\n",
    "    load_weights_path = os.path.join('weights', f'weights_{parameters_name}.{model_save_type}')\n",
    "\n",
    "    siamese = SiameseNetwork(seed=seed, width=WIDTH, height=HEIGHT, cells=CEELS, loss=loss_type, metrics=['accuracy'],\n",
    "                             optimizer=Adam(lr=l), dropout_rate=0.4)\n",
    "    siamese.fit(weights_file=load_weights_path, train_path=train_path, validation_size=validation_size,\n",
    "                batch_size=bs, epochs=ep, early_stopping=early_stopping, patience=pat,\n",
    "                min_delta=md)\n",
    "    loss, accuracy = siamese.evaluate(test_file=test_path, batch_size=bs)\n",
    "    print(f'Loss on Testing set: {loss}')\n",
    "    print(f'Accuracy on Testing set: {accuracy}')\n",
    "    # predict_pairs(model)\n",
    "    return loss, accuracy\n",
    "\n",
    "\n",
    "def run():\n",
    "    \"\"\"\n",
    "    The main function that runs the training and experiments. Uses the global variables above.\n",
    "    \"\"\"\n",
    "    # file types\n",
    "    data_set_save_type = 'pickle'\n",
    "    train_path = os.path.join(data_path, f'{train_name}.{data_set_save_type}')  # A path for the train file\n",
    "    test_path = os.path.join(data_path, f'{test_name}.{data_set_save_type}')  # A path for the test file\n",
    "    result_path = os.path.join(data_path, f'results.csv')  # A path for the train file\n",
    "    results = {'lr': [], 'batch_size': [], 'epochs': [], 'patience': [], 'min_delta': [], 'seed': [], 'loss': [],\n",
    "               'accuracy': []}\n",
    "    for l in lr:\n",
    "        for bs in batch_size:\n",
    "            for ep in epochs:\n",
    "                for pat in patience:\n",
    "                    for md in min_delta:\n",
    "                        for seed in seeds:\n",
    "                            loss, accuracy = run_combination(l=l, bs=bs, ep=ep, pat=pat, md=md, seed=seed,\n",
    "                                                             train_path=train_path, test_path=test_path)\n",
    "                            results['lr'].append(l)\n",
    "                            results['batch_size'].append(bs)\n",
    "                            results['epochs'].append(ep)\n",
    "                            results['patience'].append(pat)\n",
    "                            results['min_delta'].append(md)\n",
    "                            results['seed'].append(seed)\n",
    "                            results['loss'].append(loss)\n",
    "                            results['accuracy'].append(accuracy)\n",
    "    df_results = pd.DataFrame.from_dict(results)\n",
    "    df_results.to_csv(result_path)\n",
    "\n",
    "\n",
    "def initialize_seed(seed):\n",
    "    \"\"\"\n",
    "    Initialize all relevant environments with the seed.\n",
    "    \"\"\"\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':  if( cv2.waitKey(1) & 0XFF == ord('v')):\n",
    "                print('v is pressed')\n",
    "                anchor,frame =preprocess(frame)\n",
    "                if( model.predict([anchor,frame])>=0.5):\n",
    "                    print(True)\n",
    "    \n",
    "    seeds = [0]\n",
    "    lr = [0.00005]\n",
    "    batch_size = [32]\n",
    "    epochs = [10]\n",
    "    patience = [5]\n",
    "    min_delta = [0.01]\n",
    "\n",
    "    print(os.name)\n",
    "    start_time = time.time()\n",
    "    print('Starting the experiments')\n",
    "    run()\n",
    "    print(f'Total Running Time: {time.time() - start_time}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6c168c52-fd77-4b72-9900-87d48cab5afe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.utils.plot_model(model,\"model.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b95faf89-4fe7-4850-ada0-e920efe38673",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-06 21:16:35.459279: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 150994944 exceeds 10% of free system memory.\n",
      "2023-07-06 21:16:35.479886: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 150994944 exceeds 10% of free system memory.\n",
      "2023-07-06 21:16:35.479947: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 150994944 exceeds 10% of free system memory.\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model('saved_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "74a9cb07-e408-4335-86ac-034ab10b31e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 198ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.30333441]], dtype=float32)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict([img1,img2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51b4fdb7-d3ac-45c9-a8ff-a5f5f3c56b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a4d9512-07f6-4e36-a9d5-425803d74623",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image,ImageOps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551b668f-c335-418c-b859-fb2239a74769",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "0adcf2d7-112b-4dbf-a09b-de6910ab96ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "img2 = np.expand_dims(np.expand_dims(img2,0),3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a2815ad1-af44-4b35-ab2b-d6ad53683280",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v is pressed\n",
      "Same person\n",
      "v is pressed\n",
      "Same person\n",
      "v is pressed\n",
      "Same person\n",
      "v is pressed\n",
      "Same person\n",
      "v is pressed\n",
      "Same person\n",
      "v is pressed\n",
      "Same person\n",
      "v is pressed\n",
      "Same person\n",
      "v is pressed\n",
      "Same person\n",
      "v is pressed\n",
      "Same person\n",
      "v is pressed\n",
      "Same person\n",
      "v is pressed\n",
      "Same person\n",
      "v is pressed\n",
      "Same person\n",
      "v is pressed\n",
      "Same person\n",
      "v is pressed\n",
      "Same person\n",
      "v is pressed\n",
      "Same person\n",
      "v is pressed\n",
      "Same person\n",
      "v is pressed\n",
      "Same person\n",
      "v is pressed\n",
      "Same person\n",
      "v is pressed\n",
      "Same person\n",
      "v is pressed\n",
      "Same person\n",
      "v is pressed\n",
      "Same person\n",
      "v is pressed\n",
      "Same person\n",
      "v is pressed\n",
      "Same person\n",
      "v is pressed\n",
      "Differant person\n",
      "v is pressed\n",
      "Differant person\n",
      "v is pressed\n",
      "Differant person\n",
      "v is pressed\n",
      "Differant person\n",
      "v is pressed\n",
      "Same person\n",
      "v is pressed\n",
      "Same person\n",
      "v is pressed\n",
      "Same person\n",
      "v is pressed\n",
      "Same person\n",
      "v is pressed\n",
      "Same person\n",
      "v is pressed\n",
      "Same person\n",
      "v is pressed\n",
      "Same person\n",
      "v is pressed\n",
      "Same person\n",
      "v is pressed\n",
      "Same person\n",
      "v is pressed\n",
      "Same person\n"
     ]
    }
   ],
   "source": [
    "cam = cv2.VideoCapture(0)\n",
    "\n",
    "while cam.isOpened():\n",
    "    ret,frame = cam.read()\n",
    "    if ret:\n",
    "        cv2.imshow(\"frame\",frame)\n",
    "        try:\n",
    "            if( cv2.waitKey(1) & 0XFF == ord('v')):\n",
    "                print('v is pressed')\n",
    "                anchor,frame =preprocess(frame)\n",
    "                if( model.predict([anchor,frame],verbose=0)>=0.5):\n",
    "                    print(\"Same person\")\n",
    "                else:\n",
    "                    print(\"Differant person\")\n",
    "        except:\n",
    "            pass\n",
    "        if(cv2.waitKey(1) & 0XFF == ord('q')):\n",
    "                break\n",
    "            \n",
    "\n",
    "cam.release()\n",
    "cv2.destroyAllWindows()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e209df25-e1f2-4a60-b0f3-8f37d365ecbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(frame,anchor = 'profile.jpeg'):\n",
    "    anchor =np.expand_dims(np.expand_dims(np.asarray(ImageOps.grayscale(Image.open(anchor)).resize((105,105)),dtype='float32'),0),3)\n",
    "    frame = np.expand_dims(np.expand_dims(np.asarray(ImageOps.grayscale(Image.fromarray(frame)).resize((105,105)),dtype='float32'),0),3)\n",
    "    return anchor,frame\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c789217-7a74-408f-8756-fb6be22a29fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "0a1cb87a-7032-4769-9a23-f7375bd15159",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = np.expand_dims(np.expand_dims(np.asarray(ImageOps.grayscale(Image.fromarray(frame)).resize((105,105)),dtype='float32'),0),3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "29bd51b9-cb07-4dc2-8635-06d95641aec5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 70ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.42412263]], dtype=float32)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict([frame,anchor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "6a30ca67-5ef9-4566-9bb9-8dc8cc3ad11c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 105, 105, 1)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "3df00e91-251c-4c46-b30a-1e642b86c1f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 105, 105, 1)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anchor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae79656-0e57-4adc-ad2c-673871c5df55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8369034e-2c8b-420d-bc68-818783340186",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f33df2-71d6-448a-bbd7-290d9d8b900f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4e453e-05b1-494c-a30d-0918d2c685f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f625684f-c380-4bc8-b512-d9f836b93dbc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b083dbfa-060c-4581-afcf-314fd898f723",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989ef08d-76c6-47b3-8bb3-f46dbe42a12f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5fdd403-64e0-49b8-8ff2-ee8d59da6ebf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "266de2f4-2303-47db-b1d5-ca8caaf8a9d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffabb9ee-9566-4f80-a255-7593794fbeed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a606c1-636f-4066-aeeb-1b5264e7a27b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16bec9d0-6199-4b97-99ba-382fb774d11c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c457390a-5d0a-4a6e-8d79-dd2bd9481096",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7415e25-4cb9-4532-a8b9-88be89456ad1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ad827d-ed95-4b0d-b4a5-68d3097e0d5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e1582ed-136c-4b87-a1f6-130754a7c6b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f16ba4b-692b-4b73-8685-7c7435402b70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50822712-c8bf-4917-aec2-c2e482e3b7bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b61bad9d-53b9-40b4-8eef-5167ccad7594",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7188e3c9-e06c-4b92-aab5-b870872d7a1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c322106a-dbdd-4471-a91d-bde9d1668da8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2623a8b4-698d-48ce-89a3-c9cdab4317dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
